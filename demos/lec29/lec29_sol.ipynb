{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval using the SE formula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data set of flight delays\n",
    "united = Table.read_table('united_summer2015.csv')\n",
    "united"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sample size n = 100 of flight delays\n",
    "sample_size = 100\n",
    "my_sample = united.sample(sample_size, with_replacement = False).column(\"Delay\")\n",
    "my_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sample mean and sample SD\n",
    "my_mean = np.mean(my_sample)\n",
    "my_sd = np.std(my_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate an approximate standard error (really we need to use a t-distribution)\n",
    "approx_SE = my_sd/np.sqrt(sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate an approximate confidence interval using:  mean +/- 2 * SE\n",
    "(my_mean - 2 * approx_SE, my_mean + 2 * approx_SE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did it capture the population mean mu? \n",
    "np.mean(united.column(\"Delay\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval for a proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the flights flying to JFK airport\n",
    "united.group(\"Destination\").where(\"Destination\", \"JFK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the population proportion (pi)\n",
    "pop_proportion = np.mean(united.column('Destination') == \"JFK\")\n",
    "pop_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 900\n",
    "\n",
    "proportions_900 = make_array()\n",
    "\n",
    "for i in np.arange(10000):\n",
    "    sampled_flights = united.sample(sample_size)\n",
    "    sample_proportion = np.mean(sampled_flights.column('Destination') == \"JFK\")\n",
    "    proportions_900 = np.append(proportions_900, sample_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Sample Proportions', proportions_900).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a confidence interval\n",
    "# only valid when n * proportion and (n - 1) * proportion are greater than 10\n",
    "\n",
    "sample_size = 900\n",
    "\n",
    "one_sample = united.sample(sample_size)\n",
    "sample_proportion = np.mean(one_sample.column('Destination') == \"JFK\")\n",
    "\n",
    "SE_prop = .5/np.sqrt(sample_size)\n",
    "\n",
    "(sample_proportion - 2 * SE_prop, sample_proportion + 2 * SE_prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does the confidence interval capture the population proportion of flights going to JFK? \n",
    "pop_proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Let's revisit Galton's predictions of children's heights based on their parent's heights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "galton = Table.read_table('galton.csv')\n",
    "\n",
    "heights = Table().with_columns(\n",
    "    'MidParent', galton.column('midparentHeight'),\n",
    "    'Child', galton.column('childHeight')\n",
    "    )\n",
    "heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at a scatter plot of the relationship \n",
    "heights.scatter('MidParent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_child(h):\n",
    "    \"\"\"Return a prediction of the height of a child \n",
    "    whose parents have a midparent height of h.\n",
    "    \n",
    "    The prediction is the average height of the children \n",
    "    whose midparent height is in the range h plus or minus 0.25 inches.\n",
    "    \"\"\"\n",
    "    \n",
    "    close_points = heights.where('MidParent', are.between(h-0.5, h + 0.5))\n",
    "    return close_points.column('Child').mean()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the height for each child in the data set\n",
    "heights_with_predictions = heights.with_column(\n",
    "    'Prediction', heights.apply(predict_child, 'MidParent')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the predicted heights\n",
    "heights_with_predictions.scatter('MidParent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association\n",
    "\n",
    "Data on hybrid passenger cars sold in US 1997-2013:\n",
    "\n",
    "- `vehicle`: model of the car\n",
    "- `year`: year of manufacture\n",
    "- `msrp`: manufacturer's suggested retail price in 2013 dollars\n",
    "- `acceleration`: acceleration rate in km per hour per second\n",
    "- `mpg`: fuel econonmy in miles per gallon\n",
    "- `class`: the model's class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hybrid = Table.read_table('hybrid.csv')\n",
    "hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid.sort('msrp', descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicles with higher mpg tend to cost less on average - surprising?\n",
    "hybrid.scatter('mpg', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicles that accelerate faster tend to cost more, and have lower mpg (not as fuel efficient)\n",
    "hybrid.scatter('acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_scatter(r):\n",
    "    plots.figure(figsize=(5,5))\n",
    "    \"Generate a scatter plot with a correlation approximately r\"\n",
    "    x = np.random.normal(0, 1, 1000)\n",
    "    z = np.random.normal(0, 1, 1000)\n",
    "    y = r*x + (np.sqrt(1-r**2))*z\n",
    "    plots.scatter(x, y)\n",
    "    plots.xlim(-4, 4)\n",
    "    plots.ylim(-4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(-0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(-.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scatter(-.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the correlation coefficient\n",
    "\n",
    "To calculate the correlation coefficient r, we first convert our data to standardized units (by z-scoring out data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to standard units\n",
    "def standard_units(x):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    return (x - np.average(x))/np.std(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid2 = hybrid.select(\"msrp\", \"acceleration\")\n",
    "\n",
    "hybrid2 =  hybrid2.with_columns(\n",
    "    'msrp (standard units)', standard_units(hybrid.column('msrp')),\n",
    "    'acceleration (standard units)', standard_units(hybrid.column('acceleration')), \n",
    ")\n",
    "hybrid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of standard units does not change the point patterns\n",
    "hybrid2.scatter('acceleration (standard units)', 'msrp (standard units)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of standard units does not change the point patterns\n",
    "hybrid2.scatter('acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then calculate the product of the standardized units\n",
    "hybrid2 = hybrid2.with_column(\n",
    "    'product of standard units', hybrid2.column('acceleration (standard units)') * hybrid2.column('msrp (standard units)'))\n",
    "\n",
    "hybrid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r is the average of the products of standard units\n",
    "r = np.sum(hybrid2.column('product of standard units'))/(hybrid2.num_rows -1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create a function to calculate the correlation coefficient\n",
    "def correlation(t, label_x, label_y):\n",
    "    x_in_standard_units = standard_units(t.column(label_x))\n",
    "    y_in_standard_units = standard_units(t.column(label_y))\n",
    "    return np.sum(x_in_standard_units * y_in_standard_units)/(t.num_rows - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(hybrid, 'acceleration', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(hybrid, 'mpg', 'msrp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order doesn't matter\n",
    "correlation(hybrid, 'msrp', 'mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation cautions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation only captures linear trends\n",
    "new_x = np.arange(-4, 4.1, 0.5)\n",
    "nonlinear = Table().with_columns(\n",
    "        'x', new_x,\n",
    "        'y', new_x**2\n",
    "    )\n",
    "nonlinear.scatter('x', 'y', s=30, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation is heavily influenced by outliers\n",
    "anscombes = Table.read_table('anscombes.csv')\n",
    "data1 = anscombes.where(\"dataset\", \"I\")\n",
    "data2 = anscombes.where(\"dataset\", \"II\")\n",
    "data3 = anscombes.where(\"dataset\", \"III\")\n",
    "data4 = anscombes.where(\"dataset\", \"IV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.scatter(\"x\", \"y\")\n",
    "plots.title(\"r = \" + str(round(correlation(data1, \"x\", \"y\"), 3)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.scatter(\"x\", \"y\")\n",
    "plots.title(\"r = \" + str(round(correlation(data2, \"x\", \"y\"), 3)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.scatter(\"x\", \"y\")\n",
    "plots.title(\"r = \" + str(round(correlation(data3, \"x\", \"y\"), 3)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.scatter(\"x\", \"y\")\n",
    "plots.title(\"r = \" + str(round(correlation(data4, \"x\", \"y\"), 3)));"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
