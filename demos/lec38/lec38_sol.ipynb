{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From `datascience` to `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this semsester we have been working mostly with the `datascience` package that was created specifically for Berkeley Data8 course.\n",
    "The package is very useful for the purposes of the course; but once you start \n",
    "programming in Python on your own, most likely you will want to use the `pandas` package, which the `datascience` package is built on top of.\n",
    "`pandas` is a versatile package that is very popular among Pyhton users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you transition from `datascience` to `pandas`, today we are going to talk about basics of `pandas` and how the commands we learned from the `datascience` package translate into `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start using `pandas` we need to `import` it. The common abbreviation for `pandas` is `pd` (similar to `numpy` and `np`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import * \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataframes: Working with Tabular Data <a id='dataframes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python's `datascience` module, we used `Table` to build our dataframes and used commands such as `select()`, `where()`, `group()`, `column()` etc. In this section, we will go over some basic commands to work with tabular data in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating a Dataframe <a id='creating'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` introduces a data structure (i.e. dataframe) that represents data as a table with columns and rows. \n",
    "\n",
    "In Python's `datascience` module that is used in Data8, this is how we created tables from scratch by extending an empty table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tb = Table().with_columns([\n",
    "     'letter', ['a', 'b', 'c', 'z'],\n",
    "     'count',  [  9,   3,   3,   1],\n",
    "     'points', [  1,   2,   2,  10],\n",
    " ])\n",
    "ds_tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we can use the function `pd.DataFrame` to initialize a dataframe from a dictionary or a list-like object. Refer to the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a dictionary?** A dictionary is a Python data structure that allows us to store data as pairs of the form key:value. Keys must be unique and values can be more or less anything: integer, character, array, list, even another dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'name':'Alice', 'age':27, 'occupation':'student'} # basic dictionary\n",
    "print(dict)\n",
    "dict['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: creating a dataframe from a dictionary\n",
    "pd_df = pd.DataFrame({ 'letter' : ['a', 'b', 'c', 'z'],\n",
    "                      'count' : [  9,   3,   3,   1],\n",
    "                      'points' : [  1,   2,   2,  10]\n",
    "                      })\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More often, we will need to create a dataframe by importing data from a .csv file. In `datascience`, this is how we read data from a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_baby = Table.read_table('baby.csv')\n",
    "ds_baby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we use `pd.read_csv()` to read data from a csv file. Sometimes, depending on the data file, we may need to specify the parameters `sep`, `header` or `encoding` as well. For a full list of parameters, refer to [this guide](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading baby.csv (located in current working directory)\n",
    "pd_baby = pd.read_csv('baby.csv')\n",
    "pd_baby # displays several first and last rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_baby.head() # display the first few rows of dataframe\n",
    "pd_baby.tail(10) # display the last 10 rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary of data\n",
    "pd_baby.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read files from a URL, which is very handy. (This works for `Table.read_table` too.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: loading csv from URL\n",
    "pd_galton = pd.read_csv('https://raw.githubusercontent.com/YData123/sds123-sp22/main/demos/lec30/galton.csv')\n",
    "pd_galton.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View information about dataframe\n",
    "print(pd_galton.shape) # view dimensions (rows, cols)\n",
    "print(pd_galton.columns.values) # view column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accessing Values in Dataframe <a id='accessing'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we can use `column()` to access values in a particular column as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access column 'letter', returns array\n",
    "ds_tb.column('letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also access the column using square bracket notation:\n",
    "ds_tb['letter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas` we access a column by using the square bracket notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_galton['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pd_galton['gender']) # pandas type Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want a numpy array of column values, it is available as the name `.values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_galton['gender'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pd_galton['gender'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we used `take()` to access the rows in the Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting first two rows using Python's slicing notation\n",
    "ds_tb.take[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we can access rows and columns by their position using the `iloc` method. We need to specify the rows and columns we want in the following syntax: `df.iloc[<rows>, <columns>]`. For more information on indexing, refer to [this guide](https://pandas.pydata.org/pandas-docs/stable/indexing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting first two rows using iloc\n",
    "pd_baby.iloc[0:2, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying row indices\n",
    "pd_baby.iloc[[1, 4, 6], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting first three rows and second two columns using iloc\n",
    "pd_baby.iloc[0:3, 1:3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access a specific value in the dataframe by passing in the row and column indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value in second row, third column\n",
    "pd_baby.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Manipulating Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding columns**\n",
    "\n",
    "Adding a new column in `datascience` is done by the `with_column()` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tb = ds_tb.with_column('vowel', ['yes', 'no', 'no', 'no'])\n",
    "ds_tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we can use the bracket notation and assign a list to add to the dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "pd_df['newcol'] = [5, 6, 7, 8]\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add an existing column to the new dataframe as a new column by performing an operation on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding count * 2 to the dataframe\n",
    "pd_df['doublecount'] = pd_df['count'] * 2\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting columns**\n",
    "\n",
    "In `datascience`, we used `select()` to subset the dataframe by selecting columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tb.select(['letter', 'points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we use a double bracket notation to select columns. This returns a dataframe, unlike a Series object when we only use single bracket notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double bracket notation for new dataframe\n",
    "pd_df[['count', 'doublecount']]\n",
    "# Alternatively: \n",
    "# pd_df.iloc[:, [1,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering rows conditionally**\n",
    "\n",
    "In `datascience`, we used `where()` to select rows according to a given condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tb.where('points', 2) # rows where points == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tb.where(ds_tb['count'] < 8) # rows where count < 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we can use the bracket notation to subset the dataframe based on a condition. We first specify a condition and then subset using the bracket notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Array of booleans\n",
    "pd_baby['Maternal.Smoker'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter rows by condition Maternal.Smoker == True\n",
    "pd_baby[pd_baby['Maternal.Smoker'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering with multiple conditions\n",
    "pd_df[(pd_df['count'] < 8) & (pd_df['points'] > 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming columns**\n",
    "\n",
    "In `datascience`, we used `relabeled()` to rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'points' to 'other name'\n",
    "ds_tb.relabeled('points', 'other name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` uses `rename()`, which has an `index` parameter that needs to be set to `str` and a `columns` parameter that needs to be set to a dictionary of the names to be replaced with their replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'points' to 'other name'\n",
    "pd_df.rename(index = str, columns = {\"points\" : \"other name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we can also do\n",
    "pd_df.columns.values[2] = \"other name\"\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df.columns.values[2] = \"points\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting a Dataframe by column**\n",
    "\n",
    "In `datascience` we used `sort()` to sort a Table according to the values in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by count\n",
    "ds_tb.sort('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we use the `sort_values()` to sort by column. We need the `by` parameter to specify the row we want to sort by and the optional parameter `ascending = False` if we want to sort in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by count, descending\n",
    "pd_df.sort_values(by = ['count'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping and aggregating**\n",
    "\n",
    "In `datascience`, we used `group()` and the `collect` argument to group a Table by a column and aggregrate values in another column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by count and aggregate by sum\n",
    "ds_tb.select(['count', 'points']).group('count', collect = sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we use `groupby()` to group the dataframe. This function returns a groupby object, on which we can then call an aggregation function to return a dataframe with aggregated values for other columns. For more information, refer to the [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting two columns for brevity\n",
    "pd_df_subset = pd_df[['count', 'points']]\n",
    "pd_df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_sums_df = pd_df_subset.groupby(['count']).sum()\n",
    "count_sums_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pivot Tables**\n",
    "\n",
    "In `datascience`, we used the `pivot()` function to build contingency tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new Table\n",
    "ds_cones = Table().with_columns(\n",
    "    'Flavor', make_array('strawberry', 'chocolate', 'chocolate', \n",
    "                         'strawberry', 'chocolate', 'bubblegum'),\n",
    "    'Color', make_array('pink', 'light brown', 'dark brown', \n",
    "                        'pink', 'dark brown', 'pink'),\n",
    "    'Price', make_array(3.55, 4.75, 5.25, 5.25, 5.25, 4.75)\n",
    ")\n",
    "\n",
    "ds_cones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pivoting on color and flavor\n",
    "ds_cones.pivot(\"Flavor\", \"Color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass in the parameters `values` to specify the values in the table and `collect` to specify the aggregration function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters values and collect\n",
    "ds_cones.pivot(\"Flavor\", \"Color\", values = \"Price\", collect = np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we use `pd.pivot_table()` to create a contingency table. The argument `columns` is similar to the first argument in `datascience`'s `pivot` function and sets the column names of the pivot table. The argument `index` is similar to the second argument in `datascience`'s `pivot` function and sets the first column of the pivot table or the keys to group on. For more information, refer to the [documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframe\n",
    "pd_cones = pd.DataFrame({\"Flavor\" : ['strawberry', 'chocolate', 'chocolate', \n",
    "                                     'strawberry', 'chocolate', 'bubblegum'],\n",
    "                         \"Color\" : ['pink', 'light brown', 'dark brown', \n",
    "                                    'pink', 'dark brown', 'pink'],\n",
    "                         \"Price\" : [3.55, 4.75, 5.25, 5.25, 5.25, 4.75]})\n",
    "pd_cones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pivot table\n",
    "pd.pivot_table(pd_cones, columns = [\"Flavor\"], index = [\"Color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no data in the groups, then `pandas` will output `NaN` values (\"Not a Number\"). \n",
    "\n",
    "We can also specify the parameters like `values` (equivalent to `values` in `datascience`'s `pivot`) and `aggfunc` (equivalent to `collect` in `datascience`'s `pivot`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Additional arguments\n",
    "pd.pivot_table(pd_cones, columns = [\"Flavor\"], index = [\"Color\"], \n",
    "               values = \"Price\", aggfunc = np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joining/merging**\n",
    "\n",
    "In `datascience`, we used `join()` to join two tables based on shared values in columns. We specify the column name in the first table to match on, the name of the second table and the column name in the second table to match on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new table\n",
    "ds_ratings = Table().with_columns(\n",
    "    'Kind', make_array('strawberry', 'chocolate', 'vanilla'),\n",
    "    'Stars', make_array(2.5, 3.5, 4)\n",
    ")\n",
    "ds_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining cones and ratings\n",
    "ds_cones.join(\"Flavor\", ds_ratings, \"Kind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we can use the `merge()` function to join two tables together. The first parameter is the name of the second table to join on. The parameters `left_on` and `right_on` specify the columns to use in the left and right tables respectively. There are more parameters such as `how` which specify what kind of join to perform (Inner (Default), Outer, Left, Right). For more information, refer to this [Kaggle Tutorial](https://www.kaggle.com/crawford/python-merge-tutorial/notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new ratings df\n",
    "pd_ratings = pd.DataFrame({\"Kind\" : ['strawberry', 'chocolate', 'vanilla'],\n",
    "                           \"Stars\" : [2.5, 3.5, 4]})\n",
    "pd_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging cones and ratings\n",
    "pd_cones.merge(pd_ratings, left_on = \"Flavor\", right_on = \"Kind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `datascience`, we learned to plot data using histograms, line plots, scatter plots and histograms. The corresponding functions were `hist()`, `plot()`, `scatter()` and `barh()`. Plotting methods in `pandas` are nearly identical to `datascience` since both build on the library `matplotlib`\n",
    "\n",
    "In this section we will go through examples of such plots in `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Histograms\n",
    "\n",
    "In `datascience`, we used `hist()` to create a histogram. In this example, we will be using data from `baby.csv`. Recall that the baby data set contains data on a random sample of 1,174 mothers and their newborn babies. The column `Birth.Weight` contains the birth weight of the baby, in ounces; `Gestational.Days` is the number of gestational days, that is, the number of days the baby was in the womb. There is also data on maternal age, maternal height, maternal pregnancy weight, and whether or not the mother was a smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "ds_baby = Table.read_table('baby.csv')\n",
    "ds_baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a histogram\n",
    "ds_baby.hist('Birth.Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we use `hist()` to create histograms, just like `datascience`. Refer to the [documentation](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.hist.html) for a full list of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a histogram\n",
    "pd_baby.hist('Birth.Weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Line Plots\n",
    "\n",
    "In `datascience`, we used `plot()` to create a line plot of numerical values. In this example, we will be using census data and plot variables such as Age in a line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot in datascience\n",
    "ds_census = Table.read_table(\"https://raw.githubusercontent.com/YData123/sds123-sp21/main/demos/lec07/nc-est2014-agesex-res.csv\").select(['SEX', 'AGE', 'POPESTIMATE2014'])\n",
    "ds_children = ds_census.where('SEX', are.equal_to(0)).where('AGE', are.below(19)).drop('SEX')\n",
    "ds_children.plot('AGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we can use `plot.line()` to create line plots. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.line.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot in pandas\n",
    "pd_census = pd.read_csv(\"https://raw.githubusercontent.com/YData123/sds123-sp21/main/demos/lec07/nc-est2014-agesex-res.csv\")[[\"SEX\", \"AGE\", \"POPESTIMATE2014\"]]\n",
    "pd_children = pd_census[(pd_census.SEX == 0) & (pd_census.AGE < 19)].drop(\"SEX\", axis = 1)\n",
    "pd_children.plot.line(x = \"AGE\", y = \"POPESTIMATE2014\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Scatter Plots\n",
    "\n",
    "In `datascience`, we used `scatter()` to create a scatter plot of two numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_football = Table.read_table('https://raw.githubusercontent.com/YData123/sds123-sp22/main/demos/lec19/deflategate.csv')\n",
    "ds_football"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_football.scatter('Blakeman', 'Prioleau')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, we use `plot.scatter()` to create a scatter plot. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.scatter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_football = pd.read_csv('https://raw.githubusercontent.com/YData123/sds123-sp22/main/demos/lec19/deflategate.csv')\n",
    "pd_football.plot.scatter(x = \"Blakeman\", y = \"Prioleau\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Bar Plots\n",
    "\n",
    "In `datascience`, we used `barh()` to create a horizontal bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tb.barh(\"letter\", \"points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas', we use `plot.barh()` to create a bar chart. For a full list of parameters, refer to the [documentation](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.DataFrame.plot.barh.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df.plot.barh(x = 'letter', y = 'points');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "Here is a list of useful Pandas resources:\n",
    "\n",
    "- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [Dataquest Pandas Tutorial](https://www.dataquest.io/blog/pandas-python-tutorial/)\n",
    "- [Pandas Cookbook](http://nbviewer.jupyter.org/github/jvns/pandas-cookbook/tree/master/cookbook/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
