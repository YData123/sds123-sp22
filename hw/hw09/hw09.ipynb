{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 9: Central Limit Theorem\n",
    "\n",
    "**Reading**: \n",
    "* [Why the mean matters](https://inferentialthinking.com/chapters/14/Why_the_Mean_Matters.html)\n",
    "\n",
    "\n",
    "**Deadline:** This assignment is due **Sunday, April 17th at 11pm.** \n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. The drop-in office hours schedule can be found on [Canvas](https://yale.instructure.com/courses/76050). You can also post questions or start discussions on [Ed Discussion](https://edstem.org/us/courses/18969/discussion/).\n",
    "\n",
    "When you assign data to a name in a cell that contains information relevant to answering a question, please be sure to \"show your work\" by printing the value stored in the name (i.e., put the name by itself on a line so that the value in it is printed). \n",
    "\n",
    "\n",
    "**Submission:**\n",
    "\n",
    "Submit your assignment as a .pdf on Gradescope. You can access Gradescope through Canvas on the left-side of the class home page. The problems in each homework assignment are numbered. When submitting on Gradescope, please select the correct pages of your pdf that correspond to each problem. Failure to mark pages correctly will result in points being deducted from your homework score.\n",
    "\n",
    "**Note**: Please carefully read over all your answers in the .pdf document you create prior to uploading it to Gradescope to make sure all your answers are readable and are not cutoff. Points will be taken off for any answer that can not be read, and it will not be possible to resubmit homework answers. Adding extra space and new lines can help prevent answers from being cut off, and if you run into problems please post questions to Ed Discussions or come to office hours for help. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing the Central Limit Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem tells us that the probability distribution of the **sum** or **average** of a large random sample drawn with replacement will be roughly normal, *regardless of the distribution of the population from which the sample is drawn*.\n",
    "\n",
    "That's a pretty big claim, but the theorem doesn't stop there. It further states that the standard deviation of this normal distribution is given by \n",
    "\n",
    "$$\\frac{\\texttt{sd of the original distribution}}{\\sqrt{\\texttt{sample size}}}$$ \n",
    "\n",
    "In other words, suppose we start with *any distribution* that has standard deviation $\\sigma$, take a sample of size $n$ (where $n$ is a large number) from that distribution with replacement, and compute the **mean** of that sample. If we repeat this procedure many times, then those sample means will have a normal distribution with standard deviation $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "That's an even bigger claim than the first one! The proof of the theorem is beyond the scope of this class, but in this exercise, we will be exploring some data to see the CLT in action.\n",
    "\n",
    "**Note**: \"standard deviation of sample means\" (i.e., $\\frac{\\sigma}{\\sqrt{n}}$) is called the \"standard error\" and is denoted SE. The textbook does not use this terminology, however, it is the common term used by Statisticians. Using this term will make it easier to distinguish between different standard deviations; e.g., it will make it easier for us to distinguish between the standard deviation of the population ($\\sigma$) and the standard deviation of sample means (SE). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** The CLT only applies when sample sizes are \"sufficiently large.\" This isn't a very precise statement. Is 10 large?  How about 50?  The truth is that it depends both on the original population distribution and just how \"normal\" you want the result to look. Let's use a simulation to get a feel for how the distribution of the sample mean changes as sample size goes up.\n",
    "\n",
    "Consider a coin flip. If we say `Heads` is $1$ and `Tails` is $0$, then there's a 50% chance of getting a 1 and a 50% chance of getting a 0, which definitely doesn't match our definition of a normal distribution.  The average of several coin tosses, where Heads is 1 and Tails is 0, is equal to the proportion of heads in those coin tosses (which is equivalent to the mean value of the coin tosses), so the CLT should hold **true** if we compute the sample proportion of heads many times.\n",
    "\n",
    "Write a function called `sample_size_n` that takes in a sample size $n$. It should return an array that contains 5000 sample proportions of heads, each from $n$ coin flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_size_n(n):\n",
    "    coin_proportions = make_array(.5, .5) # our coin is fair\n",
    "    heads_proportions = make_array()\n",
    "    for i in np.arange(5000):\n",
    "        simulated_proportions = ...\n",
    "        prop_heads = ...\n",
    "        heads_proportions = ...\n",
    "    return heads_proportions\n",
    "\n",
    "\n",
    "sample_size_n(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "The code below will use the function you just defined to plot the empirical distribution of the sample mean for various sample sizes. Drag the slider or click on the number to the right to type in a sample size of your choice. The x- and y-scales are kept the same to facilitate comparisons. Notice the shape of the graph as the sample size increases and decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "from ipywidgets import interact\n",
    "\n",
    "def outer(f):\n",
    "    def graph(x):\n",
    "        bins = np.arange(-0.01,1.05,0.02)\n",
    "        sample_props = f(x)\n",
    "        Table().with_column('Sample Size: {}'.format(x), sample_props).hist(bins=bins)\n",
    "        plt.ylim(0, 30)\n",
    "        print('Sample SD:', np.std(sample_props))\n",
    "        plt.show()\n",
    "    return graph\n",
    "    \n",
    "interact(outer(sample_size_n), x=(0, 400, 1), continuous_update=False);\n",
    "\n",
    "# Min sample size is 0, max is 400\n",
    "# The graph will refresh a few times when you drag the slider around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even the means of samples of 10 items follow a roughly bell-shaped distribution.  A sample of 50 items looks quite bell-shaped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_problem_id": "clt_2"
   },
   "source": [
    "**Question 1.2.** In the plot for a sample size of 10, why are the bars spaced at intervals of .1, with gaps in between?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "clt_2"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "Now we will test the second claim of the CLT: That the SD of the sample mean (i.e., the SE) is equal to the SD of the original distribution, divided by the square root of the sample size.\n",
    "\n",
    "We have imported the flight delay data and computed its standard deviation ($\\sigma$) for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "united = Table.read_table('united_summer2015.csv')\n",
    "united_std = np.std(united.column('Delay'))\n",
    "united_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** Write a function called `empirical_se` that takes a sample size `n` as its argument. The function should simulate 500 samples with replacement of size `n` from the flight delays dataset. For each sample, it should calculate the mean flight delay. The function should then return the standard deviation of the **means of those 500 samples** (i.e., it should return the empirical standard error).\n",
    "\n",
    "*Hint:* This function will be similar to the `sample_size_n` function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_se(n):\n",
    "    sample_means = make_array()\n",
    "    for i in np.arange(500):\n",
    "        sample = ...\n",
    "        sample_mean = ...\n",
    "        sample_means = ...\n",
    "    return np.std(sample_means)\n",
    "\n",
    "empirical_se(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Now, write a function called `predict_se` to find the predicted value of the standard deviation of means (i.e., the predicted SE) according to the relationship between the SE (i.e., the standard deviation of the sample means) and sample size that is discussed [here](https://inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html) in the textbook. It takes a sample size `n` (a number) as its argument.  It returns the predicted value of the standard deviation of the mean delay time for samples of size `n` from the flight delays (represented in the table `united`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "manual_problem_id": "predict_sample_mean_sd"
   },
   "outputs": [],
   "source": [
    "def predicted_se(n):\n",
    "    ...\n",
    "\n",
    "predicted_se(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "The cell below will plot the predicted and empirical SEs for the delay data for various sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "se_table = Table().with_column('Sample Size', np.arange(1,101))\n",
    "predicted = se_table.apply(predicted_se, 'Sample Size')\n",
    "empirical = se_table.apply(empirical_se, 'Sample Size')\n",
    "se_table = se_table.with_columns('Predicted SE', predicted, 'Empirical SE', empirical)\n",
    "se_table.scatter('Sample Size')\n",
    "plt.ylabel(\"Standard error, SE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** Do our predicted and empirical SE values match? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "clt_5"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Polling and the Normal Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** Michelle is a statistical consultant, and she works for a group that supports Proposition 68 (which would mandate labeling of all horizontal or vertical axes), called Yes on 68.  They want to know how many Californians will vote for the proposition.\n",
    "\n",
    "Michelle polls a uniform random sample of all California voters, and she finds that 210 of the 400 sampled voters will vote in favor of the proposition. Fill in the code below to form a table with 3 columns: the first two columns should be identical to `sample`. The third column should be named `Proportion` and have the proportion of total voters that chose each option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Table().with_columns(\n",
    "    \"Vote\",  make_array(\"Yes\", \"No\"),\n",
    "    \"Count\", make_array(210,   190))\n",
    "sample_size = ...\n",
    "sample_with_proportions = ...\n",
    "sample_with_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** She then wants to use 10,000 bootstrap resamples to compute a confidence interval for the proportion of all California voters who will vote Yes.  Fill in the next cell to simulate an  empirical distribution of Yes proportions with 10,000 resamples. In other words, use bootstrap resampling to simulate 10,000 election outcomes, and populate `resample_yes_proportions` with the yes proportion of each bootstrap resample. Then, visualize `resample_yes_proportions` with a histogram. You should see a bell shaped curve centered near the proportion of Yes in the original sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_yes_proportions = make_array()\n",
    "for i in np.arange(10000):\n",
    "    resample = ...\n",
    "    resample_yes_proportions = ...\n",
    "Table().with_column(\"Resample Yes proportion\", resample_yes_proportions).hist(bins=np.arange(.2, .8, .01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Why does the Central Limit Theorem (CLT) apply in this situation, and how does it explain the distribution we see above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "manual_problem_id": "polling_3"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "In a population whose members are 0 and 1, there is a simple formula for the standard deviation ($\\sigma$) of that population:\n",
    "\n",
    "$$\\texttt{standard deviation} = \\sqrt{(\\text{proportion of 0s}) \\times (\\text{proportion of 1s})}$$\n",
    "\n",
    "(Figuring out this formula, starting from the definition of the standard deviation, is an fun exercise for those who enjoy algebra.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Using only the CLT and the numbers of Yes and No voters in our sample of 400, compute (*algebraically*) a number `approximate_se` that's the predicted standard deviation of the array `resample_yes_proportions` according to the Central Limit Theorem. **Do not access the data in `resample_yes_proportions` in any way.** Remember that a predicted standard deviation of the sample means (i.e., the predicted standard error, SE) can be computed from the population SD and the size of the sample. \n",
    "\n",
    "Also remember that if we do not know the population SD, we can use the sample SD as a reasonable approximation in its place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximate_se = ...\n",
    "approximate_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Compute the SD of the array `resample_yes_proportions` which will act as an approximation to the true SE of the possible sample proportions (i.e., you should use `resample_yes_proportions` here). This will help verify whether your answer to question 2.2 is approximately correct.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_se = ...\n",
    "resampled_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6.** **Again, without accessing `resample_yes_proportions` in any way**, compute an approximate 95% confidence interval for the proportion of Yes voters in California using the Central Limit Theorem and `approximate_se`.\n",
    "\n",
    "The cell below draws your interval as a red bar below the histogram of `resample_yes_proportions`; use that to verify that your answer looks right.\n",
    "\n",
    "*Hint:* How many SDs corresponds to 95% of the distribution promised by the CLT? Recall the discussion in the textbook <a href = \"https://inferentialthinking.com/chapters/14/3/SD_and_the_Normal_Curve.html\"> here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = ...\n",
    "upper_limit = ...\n",
    "print('lower:', lower_limit, 'upper:', upper_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Run this cell to plot your confidence interval.\n",
    "Table().with_column(\"Resample Yes proportion\", resample_yes_proportions).hist(bins=np.arange(.2, .8, .01))\n",
    "plt.plot(make_array(lower_limit, upper_limit), make_array(0, 0), c='r', lw=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"hide\">\\pagebreak</div>\n",
    "Your confidence interval should overlap the number 0.5.  That means we can't be very sure whether Proposition 68 is winning, even though the sample Yes proportion is a bit above 0.5.\n",
    "\n",
    "The Yes on 68 campaign really needs to know whether they're winning.  It's impossible to be absolutely sure without polling the whole population, but they'd be okay if the standard error was only 0.005.  They ask Michelle to run a new poll with a sample size that's large enough to achieve that.  (Polling is expensive, so the sample also shouldn't be bigger than necessary.)\n",
    "\n",
    "Michelle consults Chapter 14 of your textbook.  Instead of making the conservative assumption that the population standard deviation is 0.5 (coding Yes voters as 1 and No voters as 0), she decides to assume that it's equal to the standard deviation of the sample,\n",
    "\n",
    "$$\\sqrt{(\\text{Yes proportion in the sample}) \\times (\\text{No proportion in the sample})}.$$\n",
    "\n",
    "Under that assumption, Michelle decides that a sample of 9,975 would suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7.** Does Michelle's sample size achieve the desired standard error? What standard error would you achieve with a smaller sample size? A higher sample size? To explore this, first compute the standard error obtained by using Michelle's sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_population_sd = ...\n",
    "michelle_sample_size = ...\n",
    "michelle_se = ...\n",
    "print(\"With Michelle's sample size, you would predict a SE of %f.\" % michelle_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, compute the SE that you would get from a smaller sample size. Ideally, you should pick a number that is significantly smaller, but any sample size smaller than Michelle's will do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T04:35:47.010246Z",
     "start_time": "2018-03-20T04:35:47.002724Z"
    },
    "deletable": false,
    "manual_problem_id": "smaller_sample_size"
   },
   "outputs": [],
   "source": [
    "smaller_sample_size = ...\n",
    "smaller_se = ...\n",
    "print(\"With this smaller sample size, you would predict an SE of %f\" % smaller_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the SE that you would get from a larger sample size. Here, a number that is significantly larger would make any difference more obvious, but any sample size larger than Michelle's will do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-20T04:35:48.098047Z",
     "start_time": "2018-03-20T04:35:48.089414Z"
    },
    "deletable": false,
    "manual_problem_id": "larger_sample_mean_sd"
   },
   "outputs": [],
   "source": [
    "larger_sample_size = ...\n",
    "larger_se = ...\n",
    "print(\"With this larger sample size, you would predict an SE of %f\" % larger_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reflection\n",
    "\n",
    "Please reflect on how the homework went by going to Canvas, going to the Quizzes link, and clicking on [Reflection on homework 9](https://yale.instructure.com/courses/76050/quizzes/52315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 4. Submission\n",
    "\n",
    "Once you're finished, submit your assignment as a .pdf (download as .html, then print to save as a .pdf) on Gradescope."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
